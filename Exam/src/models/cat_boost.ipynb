{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor, BaggingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder, FunctionTransformer, RobustScaler\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "# from dython.nominal import associations\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "print(optuna.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_626490/2339654456.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  all_data['as'] = all_data['store_name'].str.contains(r\"\\b(AS)\\b\", case=False, regex=True)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../own_data/all_with_stores_pop.csv\")\n",
    "all_data.set_index([\"dataset\", \"range_index\"], inplace=True)\n",
    "all_data['in_mall'] = all_data['mall_name'].notna()\n",
    "all_data['in_chain'] = all_data['chain_name'].notna()\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"Mangler type\")\n",
    "all_data['mall_name'] = all_data['mall_name'].fillna(\"None\")\n",
    "# all_data['address'] = all_data['address'].fillna(\"None\")\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"None\")\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"None\")\n",
    "all_data['as'] = all_data['store_name'].str.contains(r\"\\b(AS)\\b\", case=False, regex=True)\n",
    "all_data['chain_name'] = all_data['chain_name'].fillna(\"None\")\n",
    "all_data['busstop_id'] = all_data['busstop_id'].map(str)\n",
    "all_data['lv1'] = all_data['lv1'].map(str)\n",
    "all_data['lv2'] = all_data['lv2'].map(str)\n",
    "all_data['lv3'] = all_data['lv3'].map(str)\n",
    "all_data['lv4'] = all_data['lv4'].map(str)\n",
    "all_data.drop(columns=[\n",
    "    'store_name', \n",
    "    'stopplace_type', \n",
    "    'address', \n",
    "    \"importance_level\", \n",
    "    \"mall_name\", \n",
    "    \"busstop_id\", \n",
    "    # 'other_stores_50', 'buss_stops_1000', 'buss_stops_300',\n",
    "    # \"municipality_name\", \n",
    "    \"lv1\", \n",
    "    \"lv2\", \n",
    "   #  \"lv3\", \n",
    "    \"grunnkrets_id\", \n",
    "   #  'distance_closest_busstop',\n",
    "    \"lat\", \n",
    "    \"lon\", \n",
    "    \"area_km2\", \n",
    "    # 'other_stores_50', \n",
    "    # 'buss_stops_1000', 'couple_children_0_to_5_years', 'couple_children_18_or_above',\n",
    "    'couple_children_6_to_17_years', 'couple_without_children_x',\n",
    "    'single_parent_children_0_to_5_years',\n",
    "    'single_parent_children_18_or_above',\n",
    "    'single_parent_children_6_to_17_years', 'singles_x', 'singles_y', 'couple_without_children_y', 'couple_with_children',\n",
    "    'other_households', \n",
    "    'single_parent_with_children',\n",
    "    'couple_children_0_to_5_years', 'couple_children_18_or_above',\n",
    "    'side_placement',\n",
    "      #  'num_of_buss_stops_close', \n",
    "      #  'district_age_0-14_distribution',\n",
    "      #  'district_age_15-34_distribution', 'district_age_35-64_distribution',\n",
    "      #  'district_age_65-90_distribution', \n",
    "      'grunnkrets_population',\n",
    "      #  'municipality_density', \n",
    "      #  'district_density',\n",
    "       'all_households',\n",
    "        'lv1_population_district_div_count_stores',\n",
    "       'lv2_population_district_div_count_stores',\n",
    "       'lv1_population_municipality_div_count_stores',\n",
    "       'lv2_population_municipality_div_count_stores',\n",
    "       'in_mall',\n",
    "      #  'lv3_population_district_div_count_stores',\n",
    "      #  'lv4_population_district_div_count_stores',\n",
    "      #  'lv3_population_municipality_div_count_stores',\n",
    "      #  'lv4_population_municipality_div_count_stores',\n",
    "    # 'other_stores_1000', \n",
    "    # 'other_stores_250',\n",
    "   #  'municipality_population', \n",
    "   #  'district_population', \n",
    "   #  'other_stores_100',\n",
    "\n",
    "    'district_area',\n",
    "    'municipality_area',\n",
    "    # 'in_mall',\n",
    "      #  'in_chain',\n",
    "    # 'buss_stops_300'\n",
    "   #  'lv3'\n",
    "\n",
    "    ], inplace=True)\n",
    "\n",
    "data_with_label = all_data.loc[[\"train\"]]\n",
    "\n",
    "data_with_label.set_index('store_id', inplace=True)\n",
    "data_without_label = all_data.loc[['test']]\n",
    "data_without_label.set_index('store_id', inplace=True)\n",
    "data_without_label.drop(columns=[\"revenue\"], inplace=True)\n",
    "\n",
    "X, y = data_with_label.loc[:, data_with_label.columns != 'revenue'], data_with_label['revenue']\n",
    "\n",
    "data_train, data_test = train_test_split(data_with_label, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = data_train.loc[:, data_train.columns != 'revenue'], data_train['revenue']\n",
    "X_test, y_test = data_test.loc[:, data_test.columns != 'revenue'], data_test['revenue']\n",
    "test_x_lv4 =[]\n",
    "test_y_lv4 = []\n",
    "# d = [\"1.1.6.2\"]\n",
    "plaace_lv4 = ['1.1.1.0', '1.1.2.0', '1.1.3.0', '1.1.4.0', '1.1.5.0', '1.1.6.1',\n",
    "       '1.1.6.2', '1.1.6.3', '1.1.6.4', '1.1.7.0', '1.1.9.0', '1.2.1.0',\n",
    "       '1.2.2.0', '1.2.3.0', '1.2.4.0', '1.3.1.0', '1.3.2.0', '1.4.1.0',\n",
    "       '1.4.2.0', '2.1.1.0', '2.1.2.0', '2.1.3.0', '2.1.4.0', '2.1.5.0',\n",
    "       '2.1.6.0', '2.1.7.0', '2.2.1.0', '2.2.2.0', '2.2.4.0', '2.3.1.0',\n",
    "       '2.3.2.0', '2.3.3.0', '2.3.4.0', '2.3.5.0', '2.4.1.0', '2.4.2.0',\n",
    "       '2.4.3.0', '2.4.4.0', '2.4.5.0', '2.4.6.0', '2.5.2.0', '2.6.1.0',\n",
    "       '2.6.2.0', '2.6.3.1', '2.6.3.2', '2.6.3.3', '2.6.4.0', '2.6.5.0',\n",
    "       '2.6.6.1', '2.6.6.2', '2.7.1.0', '2.7.2.0', '2.7.3.0', '2.7.4.0',\n",
    "       '2.7.5.0', '2.7.6.0', '2.8.1.0', '2.8.10.0', '2.8.11.2', '2.8.2.0',\n",
    "       '2.8.3.0', '2.8.4.0', '2.8.5.0', '2.8.6.0', '2.8.7.0', '2.9.1.0',\n",
    "       '2.9.2.0', '2.9.3.0', '2.9.4.0', '2.9.5.0', '2.9.7.0', '2.9.8.0',\n",
    "       '2.9.9.0', '3.2.1.0', '3.2.2.0', '3.2.4.0', '3.3.2.0', '3.3.3.0',\n",
    "       '3.3.4.0', '3.3.5.0', '3.3.6.0', '3.3.7.0', '3.4.2.0', '3.4.3.0',\n",
    "       '3.6.1.0']\n",
    "# for lv_4 in plaace_lv4:\n",
    "#    lv4_data = data_test[data_test[\"lv4\"] == lv_4]\n",
    "#    test_slit_x_lv4, test_split_y_lv4 = lv4_data.loc[:, lv4_data.columns != 'revenue'], lv4_data['revenue']\n",
    "#    test_x_lv4.append(test_slit_x_lv4)\n",
    "#    test_y_lv4.append(test_split_y_lv4)\n",
    "y_train_scaled = np.log1p(y_train)\n",
    "y_test_scaled = np.log1p(y_test)\n",
    "y_scaled = np.log1p(y)\n",
    "\n",
    "\n",
    "# Comment in this when testing on test dataset to kaggle\n",
    "# X_train = X\n",
    "# y_train = y\n",
    "# y_train_scaled = y_scaled\n",
    "# X_test = data_without_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://habr.com/ru/sandbox/163469/\n",
    "import math\n",
    "class RMSLE(object):\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "\n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            val = max(approxes[index], 0)\n",
    "            der1 = math.log1p(targets[index]) - math.log1p(max(0, approxes[index]))\n",
    "            der2 = -1 / (max(0, approxes[index]) + 1)\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "        \n",
    "class RMSLE_val(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return np.sqrt(error / (weight + 1e-38))\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * ((math.log1p(max(0, approx[i])) - math.log1p(max(0, target[i])))**2)\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error \n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): n-dimensional vector of ground-truth values \n",
    "        y_pred (np.array): n-dimensional vecotr of predicted values \n",
    "    \n",
    "    Returns:\n",
    "        A scalar float with the rmsle value \n",
    "    \n",
    "    Note: You can alternatively use sklearn and just do: \n",
    "        `sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5`\n",
    "    \"\"\"\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    assert (y_true >= 0).all(), 'Received negative y_true values'\n",
    "    assert (y_pred >= 0).all(), 'Received negative y_pred values'\n",
    "    assert y_true.shape == y_pred.shape, 'y_true and y_pred have different shapes'\n",
    "    y_true_log1p = np.log1p(y_true)  # log(1 + y_true)\n",
    "    y_pred_log1p = np.log1p(y_pred)  # log(1 + y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_pred_log1p - y_true_log1p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "numeric_features = list(numeric_features.to_numpy())\n",
    "\n",
    "print(len(numeric_features))\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", RobustScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X.select_dtypes(include=[np.object0]).columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),\n",
    "        (\"onehotencoding\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "categorical_features_include_bool = list(categorical_features.to_numpy())\n",
    "categorical_features_include_bool.extend(list(X.select_dtypes(include=[np.bool8]).columns.to_numpy()))\n",
    "categorical_transformer_ordinal = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "preprocessor_ordinal = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer_ordinal, categorical_features_include_bool)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# print((categorical_features_include_bool))\n",
    "\n",
    "categorical_mask = [True] * len(categorical_features_include_bool) + [False] * len(numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ft = preprocessor.fit_transform(X_train)\n",
    "X_test_ft = preprocessor.transform(X_test)\n",
    "X_train_ft1, X_val_ft, y_train_scaled1, y_val_scaled = train_test_split(X_train_ft, y_train_scaled, test_size=0.2, random_state=42)\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "        param = {\n",
    "                \"loss_function\": trial.suggest_categorical(\"loss_function\", [\"Huber:delta=0.5\", \"RMSE\"]),\n",
    "                \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n",
    "                \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "                \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "                \"bootstrap_type\": trial.suggest_categorical(\n",
    "                \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "                ),\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "                \"used_ram_limit\": \"3gb\",\n",
    "                \"eval_metric\": \"RMSE\",\n",
    "                \"verbose\": 0,\n",
    "        }\n",
    "        if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "                param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "        elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "                param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
    "\n",
    "        pruning_callback = CatBoostPruningCallback(trial, \"RMSE\")\n",
    "        cat = CatBoostRegressor(**param)\n",
    "        cat.fit(X_train_ft1, y_train_scaled1, \n",
    "                eval_set=[(X_val_ft, y_val_scaled)],\n",
    "                verbose=0,\n",
    "                early_stopping_rounds=100,\n",
    "                callbacks=[pruning_callback])\n",
    "        pruning_callback.check_pruned()\n",
    "        # early_stopping_rounds=20)\n",
    "        # s = cross_val_score(cat, X_train_ft, y_train_scaled, cv=8, scoring=\"neg_root_mean_squared_error\", verbose=0)\n",
    "\n",
    "        preds = cat.predict(X_val_ft)\n",
    "        accuracy = rmsle(np.expm1(y_val_scaled), np.expm1(preds))\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-19 17:06:17,465]\u001b[0m A new study created in memory with name: no-name-cb7a5e62-0496-412f-ae91-dd662cb1cf7b\u001b[0m\n",
      "/tmp/ipykernel_626490/3838617249.py:23: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, \"RMSE\")\n",
      "\u001b[32m[I 2022-10-19 17:06:20,999]\u001b[0m Trial 0 finished with value: 0.7782511067493552 and parameters: {'loss_function': 'Huber:delta=0.5', 'colsample_bylevel': 0.09888416990332971, 'depth': 2, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'n_estimators': 1145}. Best is trial 0 with value: 0.7782511067493552.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:06:29,230]\u001b[0m Trial 1 finished with value: 0.7573617437559735 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.017054411898367802, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 288}. Best is trial 1 with value: 0.7573617437559735.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:06:34,499]\u001b[0m Trial 2 finished with value: 0.7703011898285894 and parameters: {'loss_function': 'Huber:delta=0.5', 'colsample_bylevel': 0.01655448756332483, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'n_estimators': 1630}. Best is trial 1 with value: 0.7573617437559735.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:07:28,159]\u001b[0m Trial 3 finished with value: 0.768964436817357 and parameters: {'loss_function': 'Huber:delta=0.5', 'colsample_bylevel': 0.04222021287875957, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'n_estimators': 1801, 'subsample': 0.16073389824140985}. Best is trial 1 with value: 0.7573617437559735.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:07:53,933]\u001b[0m Trial 4 finished with value: 0.7550398602822604 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.037284603546583715, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'n_estimators': 280}. Best is trial 4 with value: 0.7550398602822604.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:07:54,072]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:08:04,769]\u001b[0m Trial 6 finished with value: 0.7661865495337643 and parameters: {'loss_function': 'Huber:delta=0.5', 'colsample_bylevel': 0.05198105947609381, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'n_estimators': 680}. Best is trial 4 with value: 0.7550398602822604.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:08:13,030]\u001b[0m Trial 7 finished with value: 0.7574835208617112 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.031045757866860996, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'n_estimators': 1440}. Best is trial 4 with value: 0.7550398602822604.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:08:13,619]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 89.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:08:13,971]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:09:04,808]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:14:20,715]\u001b[0m Trial 11 finished with value: 0.7563564298619502 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.05287815928895029, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 307}. Best is trial 4 with value: 0.7550398602822604.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:17:55,100]\u001b[0m Trial 12 finished with value: 0.7611290468677745 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.06440250424361592, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 207}. Best is trial 4 with value: 0.7550398602822604.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:20:40,085]\u001b[0m Trial 13 finished with value: 0.7538702628030929 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.07561092093218348, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 627}. Best is trial 13 with value: 0.7538702628030929.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:03,478]\u001b[0m Trial 14 finished with value: 0.7550866745253485 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.08910275951925384, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 653}. Best is trial 13 with value: 0.7538702628030929.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:03,856]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:06,940]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 125.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:07,291]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:08,278]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:12,349]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:19,758]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 155.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:47,964]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 79.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:23:52,500]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 69.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:24:27,317]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 69.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:24:27,967]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 17:27:27,023]\u001b[0m Trial 25 finished with value: 0.7535316936089622 and parameters: {'loss_function': 'RMSE', 'colsample_bylevel': 0.047008889965374515, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'n_estimators': 337}. Best is trial 25 with value: 0.7535316936089622.\u001b[0m\n",
      "\u001b[33m[W 2022-10-19 17:30:57,805]\u001b[0m Trial 26 failed because of the following error: KeyboardInterrupt('')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/lhome/haaknes/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_626490/3838617249.py\", line 25, in objective\n",
      "    cat.fit(X_train_ft1, y_train_scaled1,\n",
      "  File \"/lhome/haaknes/.local/lib/python3.10/site-packages/catboost/core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/lhome/haaknes/.local/lib/python3.10/site-packages/catboost/core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"/lhome/haaknes/.local/lib/python3.10/site-packages/catboost/core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4622, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4671, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     pruner\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39mpruners\u001b[39m.\u001b[39mMedianPruner(n_warmup_steps\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m), direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb Cell 8\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m pruning_callback \u001b[39m=\u001b[39m CatBoostPruningCallback(trial, \u001b[39m\"\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m cat \u001b[39m=\u001b[39m CatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m cat\u001b[39m.\u001b[39;49mfit(X_train_ft1, y_train_scaled1, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         eval_set\u001b[39m=\u001b[39;49m[(X_val_ft, y_val_scaled)],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[pruning_callback])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m pruning_callback\u001b[39m.\u001b[39mcheck_pruned()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# early_stopping_rounds=20)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/cat_boost.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# s = cross_val_score(cat, X_train_ft, y_train_scaled, cv=8, scoring=\"neg_root_mean_squared_error\", verbose=0)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2356\u001b[0m         train_pool,\n\u001b[1;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2358\u001b[0m         params,\n\u001b[1;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2361\u001b[0m     )\n\u001b[1;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4622\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4671\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=15), direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=6000)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.120318\n",
      "0:\tlearn: 0.9841942\ttotal: 154ms\tremaining: 1m 3s\n",
      "2:\tlearn: 0.9114678\ttotal: 649ms\tremaining: 1m 28s\n",
      "4:\tlearn: 0.8674959\ttotal: 1.08s\tremaining: 1m 28s\n",
      "6:\tlearn: 0.8424336\ttotal: 1.4s\tremaining: 1m 20s\n",
      "8:\tlearn: 0.8165446\ttotal: 1.81s\tremaining: 1m 21s\n",
      "10:\tlearn: 0.7965408\ttotal: 2.22s\tremaining: 1m 20s\n",
      "12:\tlearn: 0.7805577\ttotal: 2.54s\tremaining: 1m 17s\n",
      "14:\tlearn: 0.7713248\ttotal: 2.88s\tremaining: 1m 15s\n",
      "16:\tlearn: 0.7591628\ttotal: 3.21s\tremaining: 1m 14s\n",
      "18:\tlearn: 0.7530541\ttotal: 3.53s\tremaining: 1m 12s\n",
      "20:\tlearn: 0.7478661\ttotal: 4.05s\tremaining: 1m 15s\n",
      "22:\tlearn: 0.7415452\ttotal: 4.47s\tremaining: 1m 15s\n",
      "24:\tlearn: 0.7359057\ttotal: 4.82s\tremaining: 1m 14s\n",
      "26:\tlearn: 0.7320694\ttotal: 5.13s\tremaining: 1m 12s\n",
      "28:\tlearn: 0.7279729\ttotal: 5.43s\tremaining: 1m 11s\n",
      "30:\tlearn: 0.7251464\ttotal: 5.76s\tremaining: 1m 10s\n",
      "32:\tlearn: 0.7224215\ttotal: 6.21s\tremaining: 1m 11s\n",
      "34:\tlearn: 0.7204802\ttotal: 6.53s\tremaining: 1m 10s\n",
      "36:\tlearn: 0.7187652\ttotal: 6.93s\tremaining: 1m 10s\n",
      "38:\tlearn: 0.7165214\ttotal: 7.26s\tremaining: 1m 9s\n",
      "40:\tlearn: 0.7150328\ttotal: 7.6s\tremaining: 1m 8s\n",
      "42:\tlearn: 0.7132340\ttotal: 7.99s\tremaining: 1m 8s\n",
      "44:\tlearn: 0.7112798\ttotal: 8.34s\tremaining: 1m 7s\n",
      "46:\tlearn: 0.7097559\ttotal: 8.69s\tremaining: 1m 7s\n",
      "48:\tlearn: 0.7085378\ttotal: 9.05s\tremaining: 1m 6s\n",
      "50:\tlearn: 0.7073028\ttotal: 9.3s\tremaining: 1m 5s\n",
      "52:\tlearn: 0.7059519\ttotal: 9.67s\tremaining: 1m 5s\n",
      "54:\tlearn: 0.7049599\ttotal: 10s\tremaining: 1m 4s\n",
      "56:\tlearn: 0.7037276\ttotal: 10.4s\tremaining: 1m 4s\n",
      "58:\tlearn: 0.7024505\ttotal: 10.8s\tremaining: 1m 4s\n",
      "60:\tlearn: 0.7012551\ttotal: 11.1s\tremaining: 1m 3s\n",
      "62:\tlearn: 0.7001244\ttotal: 11.5s\tremaining: 1m 3s\n",
      "64:\tlearn: 0.6991154\ttotal: 11.8s\tremaining: 1m 2s\n",
      "66:\tlearn: 0.6983450\ttotal: 12.1s\tremaining: 1m 2s\n",
      "68:\tlearn: 0.6974672\ttotal: 12.5s\tremaining: 1m 2s\n",
      "70:\tlearn: 0.6962507\ttotal: 12.8s\tremaining: 1m 1s\n",
      "72:\tlearn: 0.6950520\ttotal: 13.1s\tremaining: 1m\n",
      "74:\tlearn: 0.6943711\ttotal: 13.3s\tremaining: 59.5s\n",
      "76:\tlearn: 0.6935675\ttotal: 13.6s\tremaining: 58.8s\n",
      "78:\tlearn: 0.6918948\ttotal: 13.9s\tremaining: 58.2s\n",
      "80:\tlearn: 0.6903826\ttotal: 14.2s\tremaining: 57.7s\n",
      "82:\tlearn: 0.6895981\ttotal: 14.5s\tremaining: 57.1s\n",
      "84:\tlearn: 0.6888103\ttotal: 14.7s\tremaining: 56.5s\n",
      "86:\tlearn: 0.6879980\ttotal: 15s\tremaining: 56s\n",
      "88:\tlearn: 0.6874263\ttotal: 15.3s\tremaining: 55.4s\n",
      "90:\tlearn: 0.6866557\ttotal: 15.6s\tremaining: 54.9s\n",
      "92:\tlearn: 0.6857438\ttotal: 15.9s\tremaining: 54.5s\n",
      "94:\tlearn: 0.6850399\ttotal: 16.2s\tremaining: 53.9s\n",
      "96:\tlearn: 0.6843549\ttotal: 16.5s\tremaining: 53.5s\n",
      "98:\tlearn: 0.6833612\ttotal: 16.8s\tremaining: 52.9s\n",
      "100:\tlearn: 0.6826412\ttotal: 17.1s\tremaining: 52.5s\n",
      "102:\tlearn: 0.6815600\ttotal: 17.4s\tremaining: 52s\n",
      "104:\tlearn: 0.6805203\ttotal: 17.7s\tremaining: 51.5s\n",
      "106:\tlearn: 0.6795003\ttotal: 18s\tremaining: 51.1s\n",
      "108:\tlearn: 0.6787737\ttotal: 18.3s\tremaining: 50.6s\n",
      "110:\tlearn: 0.6780410\ttotal: 18.6s\tremaining: 50.2s\n",
      "112:\tlearn: 0.6770079\ttotal: 18.9s\tremaining: 49.7s\n",
      "114:\tlearn: 0.6761141\ttotal: 19.2s\tremaining: 49.4s\n",
      "116:\tlearn: 0.6756162\ttotal: 19.6s\tremaining: 49.3s\n",
      "118:\tlearn: 0.6747700\ttotal: 20s\tremaining: 49.1s\n",
      "120:\tlearn: 0.6742708\ttotal: 20.3s\tremaining: 48.7s\n",
      "122:\tlearn: 0.6735319\ttotal: 20.6s\tremaining: 48.3s\n",
      "124:\tlearn: 0.6729963\ttotal: 20.9s\tremaining: 47.8s\n",
      "126:\tlearn: 0.6719376\ttotal: 21.2s\tremaining: 47.4s\n",
      "128:\tlearn: 0.6711824\ttotal: 21.5s\tremaining: 46.9s\n",
      "130:\tlearn: 0.6707178\ttotal: 21.8s\tremaining: 46.6s\n",
      "132:\tlearn: 0.6701774\ttotal: 22.1s\tremaining: 46.2s\n",
      "134:\tlearn: 0.6698445\ttotal: 22.4s\tremaining: 45.8s\n",
      "136:\tlearn: 0.6692721\ttotal: 22.7s\tremaining: 45.4s\n",
      "138:\tlearn: 0.6685301\ttotal: 23s\tremaining: 45s\n",
      "140:\tlearn: 0.6675488\ttotal: 23.3s\tremaining: 44.6s\n",
      "142:\tlearn: 0.6669808\ttotal: 23.6s\tremaining: 44.2s\n",
      "144:\tlearn: 0.6664872\ttotal: 23.9s\tremaining: 43.9s\n",
      "146:\tlearn: 0.6660950\ttotal: 24.2s\tremaining: 43.5s\n",
      "148:\tlearn: 0.6654809\ttotal: 24.5s\tremaining: 43.1s\n",
      "150:\tlearn: 0.6650702\ttotal: 24.8s\tremaining: 42.7s\n",
      "152:\tlearn: 0.6642725\ttotal: 25.1s\tremaining: 42.3s\n",
      "154:\tlearn: 0.6634182\ttotal: 25.4s\tremaining: 41.9s\n",
      "156:\tlearn: 0.6630674\ttotal: 25.7s\tremaining: 41.5s\n",
      "158:\tlearn: 0.6619401\ttotal: 26s\tremaining: 41.2s\n",
      "160:\tlearn: 0.6611092\ttotal: 26.3s\tremaining: 40.8s\n",
      "162:\tlearn: 0.6605739\ttotal: 26.7s\tremaining: 40.5s\n",
      "164:\tlearn: 0.6599964\ttotal: 27s\tremaining: 40.3s\n",
      "166:\tlearn: 0.6597500\ttotal: 27.5s\tremaining: 40.2s\n",
      "168:\tlearn: 0.6594232\ttotal: 28.1s\tremaining: 40.2s\n",
      "170:\tlearn: 0.6591265\ttotal: 28.7s\tremaining: 40.3s\n",
      "172:\tlearn: 0.6583754\ttotal: 29.1s\tremaining: 40.1s\n",
      "174:\tlearn: 0.6577731\ttotal: 29.5s\tremaining: 39.7s\n",
      "176:\tlearn: 0.6574024\ttotal: 29.8s\tremaining: 39.4s\n",
      "178:\tlearn: 0.6567399\ttotal: 30.1s\tremaining: 39s\n",
      "180:\tlearn: 0.6564549\ttotal: 30.4s\tremaining: 38.6s\n",
      "182:\tlearn: 0.6561541\ttotal: 30.7s\tremaining: 38.2s\n",
      "184:\tlearn: 0.6547893\ttotal: 31s\tremaining: 37.9s\n",
      "186:\tlearn: 0.6545511\ttotal: 31.4s\tremaining: 37.6s\n",
      "188:\tlearn: 0.6536977\ttotal: 31.7s\tremaining: 37.3s\n",
      "190:\tlearn: 0.6534514\ttotal: 32s\tremaining: 36.9s\n",
      "192:\tlearn: 0.6528063\ttotal: 32.4s\tremaining: 36.6s\n",
      "194:\tlearn: 0.6518699\ttotal: 32.8s\tremaining: 36.3s\n",
      "196:\tlearn: 0.6513772\ttotal: 33.1s\tremaining: 35.9s\n",
      "198:\tlearn: 0.6507509\ttotal: 33.4s\tremaining: 35.6s\n",
      "200:\tlearn: 0.6505179\ttotal: 33.8s\tremaining: 35.3s\n",
      "202:\tlearn: 0.6501912\ttotal: 34.1s\tremaining: 35s\n",
      "204:\tlearn: 0.6499754\ttotal: 34.4s\tremaining: 34.6s\n",
      "206:\tlearn: 0.6496814\ttotal: 34.8s\tremaining: 34.2s\n",
      "208:\tlearn: 0.6492323\ttotal: 35s\tremaining: 33.9s\n",
      "210:\tlearn: 0.6486265\ttotal: 35.4s\tremaining: 33.5s\n",
      "212:\tlearn: 0.6484657\ttotal: 35.7s\tremaining: 33.1s\n",
      "214:\tlearn: 0.6482200\ttotal: 36s\tremaining: 32.8s\n",
      "216:\tlearn: 0.6479772\ttotal: 36.3s\tremaining: 32.4s\n",
      "218:\tlearn: 0.6472549\ttotal: 36.6s\tremaining: 32.1s\n",
      "220:\tlearn: 0.6469998\ttotal: 36.9s\tremaining: 31.7s\n",
      "222:\tlearn: 0.6467867\ttotal: 37.3s\tremaining: 31.5s\n",
      "224:\tlearn: 0.6463647\ttotal: 37.8s\tremaining: 31.2s\n",
      "226:\tlearn: 0.6459873\ttotal: 38.3s\tremaining: 31s\n",
      "228:\tlearn: 0.6454977\ttotal: 38.7s\tremaining: 30.7s\n",
      "230:\tlearn: 0.6450035\ttotal: 39s\tremaining: 30.4s\n",
      "232:\tlearn: 0.6448214\ttotal: 39.3s\tremaining: 30s\n",
      "234:\tlearn: 0.6446412\ttotal: 39.7s\tremaining: 29.7s\n",
      "236:\tlearn: 0.6443463\ttotal: 40s\tremaining: 29.4s\n",
      "238:\tlearn: 0.6441401\ttotal: 40.3s\tremaining: 29s\n",
      "240:\tlearn: 0.6439448\ttotal: 40.8s\tremaining: 28.8s\n",
      "242:\tlearn: 0.6438103\ttotal: 41.3s\tremaining: 28.5s\n",
      "244:\tlearn: 0.6435923\ttotal: 41.8s\tremaining: 28.3s\n",
      "246:\tlearn: 0.6432288\ttotal: 42.2s\tremaining: 28s\n",
      "248:\tlearn: 0.6429896\ttotal: 43.1s\tremaining: 28s\n",
      "250:\tlearn: 0.6419883\ttotal: 43.8s\tremaining: 27.9s\n",
      "252:\tlearn: 0.6413825\ttotal: 44.2s\tremaining: 27.6s\n",
      "254:\tlearn: 0.6404727\ttotal: 44.6s\tremaining: 27.3s\n",
      "256:\tlearn: 0.6401023\ttotal: 44.9s\tremaining: 26.9s\n",
      "258:\tlearn: 0.6397332\ttotal: 45.2s\tremaining: 26.5s\n",
      "260:\tlearn: 0.6391540\ttotal: 45.6s\tremaining: 26.2s\n",
      "262:\tlearn: 0.6386485\ttotal: 46s\tremaining: 25.9s\n",
      "264:\tlearn: 0.6381797\ttotal: 46.3s\tremaining: 25.5s\n",
      "266:\tlearn: 0.6379547\ttotal: 46.6s\tremaining: 25.1s\n",
      "268:\tlearn: 0.6377679\ttotal: 46.9s\tremaining: 24.8s\n",
      "270:\tlearn: 0.6371304\ttotal: 47.2s\tremaining: 24.4s\n",
      "272:\tlearn: 0.6366100\ttotal: 47.5s\tremaining: 24s\n",
      "274:\tlearn: 0.6360909\ttotal: 47.8s\tremaining: 23.6s\n",
      "276:\tlearn: 0.6358723\ttotal: 48.1s\tremaining: 23.3s\n",
      "278:\tlearn: 0.6351906\ttotal: 48.4s\tremaining: 22.9s\n",
      "280:\tlearn: 0.6347075\ttotal: 48.9s\tremaining: 22.6s\n",
      "282:\tlearn: 0.6342651\ttotal: 49.2s\tremaining: 22.3s\n",
      "284:\tlearn: 0.6341145\ttotal: 49.5s\tremaining: 21.9s\n",
      "286:\tlearn: 0.6339712\ttotal: 49.8s\tremaining: 21.5s\n",
      "288:\tlearn: 0.6338543\ttotal: 50.1s\tremaining: 21.1s\n",
      "290:\tlearn: 0.6331250\ttotal: 50.6s\tremaining: 20.9s\n",
      "292:\tlearn: 0.6329593\ttotal: 51.1s\tremaining: 20.6s\n",
      "294:\tlearn: 0.6327760\ttotal: 51.4s\tremaining: 20.2s\n",
      "296:\tlearn: 0.6324077\ttotal: 51.9s\tremaining: 19.9s\n",
      "298:\tlearn: 0.6320915\ttotal: 52.2s\tremaining: 19.6s\n",
      "300:\tlearn: 0.6319972\ttotal: 52.5s\tremaining: 19.2s\n",
      "302:\tlearn: 0.6311555\ttotal: 52.8s\tremaining: 18.8s\n",
      "304:\tlearn: 0.6303542\ttotal: 53.1s\tremaining: 18.4s\n",
      "306:\tlearn: 0.6300182\ttotal: 53.4s\tremaining: 18.1s\n",
      "308:\tlearn: 0.6292872\ttotal: 53.7s\tremaining: 17.7s\n",
      "310:\tlearn: 0.6288557\ttotal: 54s\tremaining: 17.4s\n",
      "312:\tlearn: 0.6287102\ttotal: 54.3s\tremaining: 17s\n",
      "314:\tlearn: 0.6284868\ttotal: 54.6s\tremaining: 16.6s\n",
      "316:\tlearn: 0.6283821\ttotal: 54.9s\tremaining: 16.3s\n",
      "318:\tlearn: 0.6281082\ttotal: 55.2s\tremaining: 15.9s\n",
      "320:\tlearn: 0.6279501\ttotal: 55.5s\tremaining: 15.6s\n",
      "322:\tlearn: 0.6277453\ttotal: 55.8s\tremaining: 15.2s\n",
      "324:\tlearn: 0.6272888\ttotal: 56.1s\tremaining: 14.8s\n",
      "326:\tlearn: 0.6271674\ttotal: 56.4s\tremaining: 14.5s\n",
      "328:\tlearn: 0.6267150\ttotal: 56.6s\tremaining: 14.1s\n",
      "330:\tlearn: 0.6263642\ttotal: 56.9s\tremaining: 13.8s\n",
      "332:\tlearn: 0.6259130\ttotal: 57.2s\tremaining: 13.4s\n",
      "334:\tlearn: 0.6253602\ttotal: 57.5s\tremaining: 13.1s\n",
      "336:\tlearn: 0.6251935\ttotal: 57.8s\tremaining: 12.7s\n",
      "338:\tlearn: 0.6242591\ttotal: 58.1s\tremaining: 12.3s\n",
      "340:\tlearn: 0.6235812\ttotal: 58.4s\tremaining: 12s\n",
      "342:\tlearn: 0.6233061\ttotal: 58.7s\tremaining: 11.6s\n",
      "344:\tlearn: 0.6229772\ttotal: 59s\tremaining: 11.3s\n",
      "346:\tlearn: 0.6227298\ttotal: 59.3s\tremaining: 10.9s\n",
      "348:\tlearn: 0.6225256\ttotal: 59.6s\tremaining: 10.6s\n",
      "350:\tlearn: 0.6222493\ttotal: 59.9s\tremaining: 10.2s\n",
      "352:\tlearn: 0.6221573\ttotal: 1m\tremaining: 9.88s\n",
      "354:\tlearn: 0.6218759\ttotal: 1m\tremaining: 9.54s\n",
      "356:\tlearn: 0.6217176\ttotal: 1m\tremaining: 9.19s\n",
      "358:\tlearn: 0.6216181\ttotal: 1m 1s\tremaining: 8.84s\n",
      "360:\tlearn: 0.6214459\ttotal: 1m 1s\tremaining: 8.49s\n",
      "362:\tlearn: 0.6212719\ttotal: 1m 1s\tremaining: 8.15s\n",
      "364:\tlearn: 0.6210153\ttotal: 1m 1s\tremaining: 7.8s\n",
      "366:\tlearn: 0.6209087\ttotal: 1m 2s\tremaining: 7.46s\n",
      "368:\tlearn: 0.6206877\ttotal: 1m 2s\tremaining: 7.12s\n",
      "370:\tlearn: 0.6201485\ttotal: 1m 2s\tremaining: 6.77s\n",
      "372:\tlearn: 0.6193889\ttotal: 1m 3s\tremaining: 6.43s\n",
      "374:\tlearn: 0.6192563\ttotal: 1m 3s\tremaining: 6.09s\n",
      "376:\tlearn: 0.6191684\ttotal: 1m 3s\tremaining: 5.74s\n",
      "378:\tlearn: 0.6189945\ttotal: 1m 3s\tremaining: 5.4s\n",
      "380:\tlearn: 0.6184490\ttotal: 1m 4s\tremaining: 5.06s\n",
      "382:\tlearn: 0.6182484\ttotal: 1m 4s\tremaining: 4.72s\n",
      "384:\tlearn: 0.6180106\ttotal: 1m 4s\tremaining: 4.38s\n",
      "386:\tlearn: 0.6178176\ttotal: 1m 5s\tremaining: 4.04s\n",
      "388:\tlearn: 0.6168858\ttotal: 1m 5s\tremaining: 3.7s\n",
      "390:\tlearn: 0.6164911\ttotal: 1m 5s\tremaining: 3.36s\n",
      "392:\tlearn: 0.6162796\ttotal: 1m 6s\tremaining: 3.02s\n",
      "394:\tlearn: 0.6161202\ttotal: 1m 6s\tremaining: 2.69s\n",
      "396:\tlearn: 0.6157647\ttotal: 1m 6s\tremaining: 2.35s\n",
      "398:\tlearn: 0.6155847\ttotal: 1m 6s\tremaining: 2.01s\n",
      "400:\tlearn: 0.6151068\ttotal: 1m 7s\tremaining: 1.68s\n",
      "402:\tlearn: 0.6147400\ttotal: 1m 7s\tremaining: 1.34s\n",
      "404:\tlearn: 0.6144635\ttotal: 1m 7s\tremaining: 1s\n",
      "406:\tlearn: 0.6143541\ttotal: 1m 8s\tremaining: 669ms\n",
      "408:\tlearn: 0.6141472\ttotal: 1m 8s\tremaining: 334ms\n",
      "410:\tlearn: 0.6136466\ttotal: 1m 8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1f1150cffa0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param = {'loss_function': 'RMSE', 'colsample_bylevel': 0.05980735726255026, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS',\"eval_metric\": \"RMSE\",\"n_estimators\": 411 }\n",
    "cat = CatBoostRegressor(**param)\n",
    "cat.fit(X_train_ft,\n",
    "        y_train_scaled,\n",
    "        # eval_set=[(X_val_ft, y_val_scaled)],\n",
    "        verbose=2,\n",
    "        # early_stopping_rounds=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7090734450516947\n"
     ]
    }
   ],
   "source": [
    "preds = cat.predict(X_test_ft)\n",
    "accuracy = rmsle(np.expm1(y_test_scaled), np.expm1(preds))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tdt4173')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a1013845248e30736e18085f9632598af74800f63e4cdc02bac7c14c90f9e84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
