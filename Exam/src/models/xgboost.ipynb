{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor, XGBClassifier \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder, GLMMEncoder\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel, mutual_info_classif\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error \n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): n-dimensional vector of ground-truth values \n",
    "        y_pred (np.array): n-dimensional vecotr of predicted values \n",
    "    \n",
    "    Returns:\n",
    "        A scalar float with the rmsle value \n",
    "    \n",
    "    Note: You can alternatively use sklearn and just do: \n",
    "        `sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5`\n",
    "    \"\"\"\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    assert (y_true >= 0).all(), 'Received negative y_true values'\n",
    "    assert (y_pred >= 0).all(), 'Received negative y_pred values'\n",
    "    assert y_true.shape == y_pred.shape, 'y_true and y_pred have different shapes'\n",
    "    y_true_log1p = np.log1p(y_true)  # log(1 + y_true)\n",
    "    y_pred_log1p = np.log1p(y_pred)  # log(1 + y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_pred_log1p - y_true_log1p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12038, 124)\n",
      "Index(['other_stores_1000', 'other_stores_100', 'other_stores_50',\n",
      "       'buss_stops_1000', 'buss_stops_300', 'distance_closest_busstop',\n",
      "       'other_stores_250', 'area_km2', 'couple_children_0_to_5_years',\n",
      "       'couple_children_18_or_above',\n",
      "       ...\n",
      "       'age_82', 'age_83', 'age_84', 'age_85', 'age_86', 'age_87', 'age_88',\n",
      "       'age_89', 'age_90', 'num_of_buss_stops_close'],\n",
      "      dtype='object', length=114)\n",
      "(12038, 14)\n",
      "['other_stores_1000' 'other_stores_100' 'other_stores_50'\n",
      " 'distance_closest_busstop' 'other_stores_250'\n",
      " 'couple_children_0_to_5_years' 'couple_children_18_or_above'\n",
      " 'couple_children_6_to_17_years' 'couple_without_children_x'\n",
      " 'single_parent_children_18_or_above' 'singles_x' 'singles_y'\n",
      " 'couple_without_children_y' 'single_parent_with_children']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../own_data/all_merged.csv\").set_index([\"dataset\", \"range_index\"])\n",
    "df.drop(columns=['store_name', 'address', 'lat', 'lon', 'busstop_id', 'importance_level', 'stopplace_type', 'grunnkrets_id', \"side_placement\"], inplace=True)\n",
    "df['in_mall'] = df['mall_name'].notna()\n",
    "df['in_chain'] = df['chain_name'].notna()\n",
    "# df['stopplace_type'] = df['stopplace_type'].fillna(\"Mangler type\")\n",
    "df['mall_name'] = df['mall_name'].fillna(\"None\")\n",
    "#df['address'] = df['address'].fillna(\"None\")\n",
    "#df['stopplace_type'] = df['stopplace_type'].fillna(\"None\")\n",
    "\n",
    "df['chain_name'] = df['chain_name'].fillna(\"None\")\n",
    "# df['busstop_id'] = df['busstop_id'].map(str)\n",
    "df['lv1'] = df['lv1'].map(str)\n",
    "df['lv2'] = df['lv2'].map(str)\n",
    "df['lv3'] = df['lv3'].map(str)\n",
    "df['lv4'] = df['lv4'].map(str)\n",
    "\n",
    "data_with_label = df.loc[\"train\"]\n",
    "data_with_label.set_index('store_id', inplace=True)\n",
    "\n",
    "X, y = data_with_label.loc[:, data_with_label.columns != 'revenue'], data_with_label['revenue']\n",
    "\n",
    "# Numeric feature selection\n",
    "print(X.shape)\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X.select_dtypes(include=[np.object0]).columns\n",
    "print(numeric_features)\n",
    "lsvr = LinearSVR().fit(X[numeric_features], y)\n",
    "model = SelectFromModel(lsvr, prefit=True)\n",
    "X_new = model.transform(X[numeric_features])\n",
    "print(X_new.shape)\n",
    "print(model.get_feature_names_out(input_features=numeric_features))\n",
    "X_red = pd.DataFrame(data=X_new, columns=model.get_feature_names_out(input_features=numeric_features), index=X.index)\n",
    "X = X[categorical_features].join(X_red)\n",
    "\n",
    "# Combining categories\n",
    "for cat_name in categorical_features:\n",
    "    series = X[cat_name].value_counts()\n",
    "    mask = (series/series.sum() * 100).lt(.05)\n",
    "    # To replace df['column'] use np.where I.e \n",
    "    X[cat_name] = np.where(X[cat_name].isin(series[mask].index),'Other',X[cat_name])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_log = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X.select_dtypes(include=[np.object0]).columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        # (\"imputer\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),\n",
    "        (\"onehotencoding\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.338935\n",
      "0.7210650806056396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "X_train_ft = preprocessor.fit_transform(X_train)\n",
    "X_test_ft = preprocessor.transform(X_test)\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    SelectPercentile(score_func=f_regression, percentile=84),\n",
    "    XGBRegressor(learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=100, n_jobs=1, objective=\"reg:squarederror\", subsample=1.0, verbosity=0)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(X_train_ft, y_train_log)\n",
    "results = exported_pipeline.predict(X_test_ft)\n",
    "print(max(results))\n",
    "print(rmsle(y_test, np.expm1(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:57:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"subsample:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "-0.745648964680766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:57:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"subsample:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "-0.7465349926406004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:57:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"subsample:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "-0.717256238410506\n",
      "[08:57:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"subsample:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7351424235834618\n",
      "[08:57:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"subsample:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haako\\Anaconda3\\envs\\tdt4173\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.710026059910413\n",
      "[0.745648964680766, 0.7465349926406004, 0.717256238410506, 0.7351424235834618, 0.710026059910413]\n",
      "Mean: 0.7309217358451494\n",
      "Std: 0.014844893767403135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "model_params = {'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 7, 'subsample:': 1, 'n_estimators':100, 'objective': 'reg:squarederror'}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "    (\"select\", SelectPercentile(score_func=f_regression, percentile=84)),\n",
    "    (\"xgbregressor\", \n",
    "    XGBRegressor(**model_params))]\n",
    ")\n",
    "def kfold_cross_validate(pipeline, X, y, n_splits=5, shuffle=True, scoring=error, random_seed=None):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_seed)\n",
    "    splits = kfold.split(X, y)\n",
    "    scores = []\n",
    "    for train, test in splits:\n",
    "        temp = X.reset_index()\n",
    "        X_train = temp.iloc[train]\n",
    "        X_test = temp.iloc[test]\n",
    "        temp_y = y.reset_index()\n",
    "        y_train = temp_y.iloc[train]\n",
    "        y_test = temp_y.iloc[test]\n",
    "        \n",
    "        X_train.set_index(\"store_id\", inplace=True), X_test.set_index(\"store_id\", inplace=True), y_train.set_index(\"store_id\", inplace=True), y_test.set_index(\"store_id\", inplace=True)\n",
    "        y_train = np.log1p(y_train)\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = scoring(y_test, pipeline.predict(X_test))\n",
    "        score_alt = make_scorer(error, greater_is_better=False)\n",
    "        print(score_alt(pipeline, X_test, y_test))\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "scores = kfold_cross_validate(pipeline, X_train, y_train, random_seed=0)\n",
    "print(scores)\n",
    "print(f\"Mean: {np.mean(scores)}\")\n",
    "print(f\"Std: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../../own_data/all_merged.csv\").set_index([\"dataset\", \"range_index\"])\n",
    "df.drop(columns=['store_name', 'address', 'lat', 'lon', 'busstop_id', 'importance_level', 'stopplace_type', 'grunnkrets_id'], inplace=True)\n",
    "df['in_mall'] = df['mall_name'].notna()\n",
    "df['in_chain'] = df['chain_name'].notna()\n",
    "# df['stopplace_type'] = df['stopplace_type'].fillna(\"Mangler type\")\n",
    "df['mall_name'] = df['mall_name'].fillna(\"None\")\n",
    "#df['address'] = df['address'].fillna(\"None\")\n",
    "#df['stopplace_type'] = df['stopplace_type'].fillna(\"None\")\n",
    "\n",
    "df['chain_name'] = df['chain_name'].fillna(\"None\")\n",
    "# df['busstop_id'] = df['busstop_id'].map(str)\n",
    "df['lv1'] = df['lv1'].map(str)\n",
    "df['lv2'] = df['lv2'].map(str)\n",
    "df['lv3'] = df['lv3'].map(str)\n",
    "df['lv4'] = df['lv4'].map(str)\n",
    "\n",
    "data_with_label = df.loc[\"train\"]\n",
    "data_with_label.set_index('store_id', inplace=True)\n",
    "\n",
    "seed = 0\n",
    "X, y = data_with_label.loc[:, data_with_label.columns != 'revenue'], data_with_label['revenue']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "y_train = np.log1p(y_train)\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = X.select_dtypes(include=[np.object0]).columns\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "    (\"xgbregressor\", XGBRegressor())])\n",
    "\n",
    "param_grid = {\n",
    "    #'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'xgbregressor__max_depth': [2, 3, 5, 7, 10],\n",
    "    'xgbregressor__n_estimators': [10, 100],\n",
    "    \"xgbregressor__objective\": [\"squareerror\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring=make_scorer(error, greater_is_better=False), verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "CPU times: total: 3.58 s\n",
      "Wall time: 24 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index([&#x27;distance_closest_busstop&#x27;, &#x27;area_km2&#x27;, &#x27;couple_children_0_to_5_years&#x27;,\n",
       "       &#x27;couple_children_18_or_above&#x27;, &#x27;couple_children_6_to_17_years&#x27;,\n",
       "       &#x27;couple_without_children_x&#x27;, &#x27;single_parent_...\n",
       "                                                     max_leaves=None,\n",
       "                                                     min_child_weight=None,\n",
       "                                                     missing=nan,\n",
       "                                                     monotone_constraints=None,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     num_parallel_tree=None,\n",
       "                                                     predictor=None,\n",
       "                                                     random_state=None,\n",
       "                                                     reg_alpha=None,\n",
       "                                                     reg_lambda=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;xgbregressor__max_depth&#x27;: [2, 3, 5, 7, 10],\n",
       "                         &#x27;xgbregressor__n_estimators&#x27;: [10, 100]},\n",
       "             scoring=make_scorer(error, greater_is_better=False), verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index([&#x27;distance_closest_busstop&#x27;, &#x27;area_km2&#x27;, &#x27;couple_children_0_to_5_years&#x27;,\n",
       "       &#x27;couple_children_18_or_above&#x27;, &#x27;couple_children_6_to_17_years&#x27;,\n",
       "       &#x27;couple_without_children_x&#x27;, &#x27;single_parent_...\n",
       "                                                     max_leaves=None,\n",
       "                                                     min_child_weight=None,\n",
       "                                                     missing=nan,\n",
       "                                                     monotone_constraints=None,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     num_parallel_tree=None,\n",
       "                                                     predictor=None,\n",
       "                                                     random_state=None,\n",
       "                                                     reg_alpha=None,\n",
       "                                                     reg_lambda=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;xgbregressor__max_depth&#x27;: [2, 3, 5, 7, 10],\n",
       "                         &#x27;xgbregressor__n_estimators&#x27;: [10, 100]},\n",
       "             scoring=make_scorer(error, greater_is_better=False), verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;distance_closest_busstop&#x27;, &#x27;area_km2&#x27;, &#x27;couple_children_0_to_5_years&#x27;,\n",
       "       &#x27;couple_children_18_or_above&#x27;, &#x27;couple_children_6_to_17_years&#x27;,\n",
       "       &#x27;couple_without_children_x&#x27;, &#x27;single_parent_children_0_to_5_years&#x27;,\n",
       "       &#x27;sing...\n",
       "                              gamma=None, gpu_id=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_to_onehot=None,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              max_leaves=None, min_child_weight=None,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              n_estimators=100, n_jobs=None,\n",
       "                              num_parallel_tree=None, predictor=None,\n",
       "                              random_state=None, reg_alpha=None,\n",
       "                              reg_lambda=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;distance_closest_busstop&#x27;, &#x27;area_km2&#x27;, &#x27;couple_children_0_to_5_years&#x27;,\n",
       "       &#x27;couple_children_18_or_above&#x27;, &#x27;couple_children_6_to_17_years&#x27;,\n",
       "       &#x27;couple_without_children_x&#x27;, &#x27;single_parent_children_0_to_5_years&#x27;,\n",
       "       &#x27;single_parent_children_18_or_above&#x27;,\n",
       "       &#x27;single_parent_children_6_to_17_years&#x27;, &#x27;singles_x&#x27;, &#x27;all_households&#x27;,\n",
       "       &#x27;singles_y&#x27;, &#x27;couple_without_children_y&#x27;, &#x27;couple_with_children&#x27;,\n",
       "       &#x27;other_households&#x27;, &#x27;single_parent_with_children&#x27;,\n",
       "       &#x27;num_of_buss_stops_close&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 Index([&#x27;chain_name&#x27;, &#x27;mall_name&#x27;, &#x27;district_name&#x27;, &#x27;municipality_name&#x27;, &#x27;lv1&#x27;,\n",
       "       &#x27;lv2&#x27;, &#x27;lv3&#x27;, &#x27;lv4&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;distance_closest_busstop&#x27;, &#x27;area_km2&#x27;, &#x27;couple_children_0_to_5_years&#x27;,\n",
       "       &#x27;couple_children_18_or_above&#x27;, &#x27;couple_children_6_to_17_years&#x27;,\n",
       "       &#x27;couple_without_children_x&#x27;, &#x27;single_parent_children_0_to_5_years&#x27;,\n",
       "       &#x27;single_parent_children_18_or_above&#x27;,\n",
       "       &#x27;single_parent_children_6_to_17_years&#x27;, &#x27;singles_x&#x27;, &#x27;all_households&#x27;,\n",
       "       &#x27;singles_y&#x27;, &#x27;couple_without_children_y&#x27;, &#x27;couple_with_children&#x27;,\n",
       "       &#x27;other_households&#x27;, &#x27;single_parent_with_children&#x27;,\n",
       "       &#x27;num_of_buss_stops_close&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" ><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;chain_name&#x27;, &#x27;mall_name&#x27;, &#x27;district_name&#x27;, &#x27;municipality_name&#x27;, &#x27;lv1&#x27;,\n",
       "       &#x27;lv2&#x27;, &#x27;lv3&#x27;, &#x27;lv4&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-107\" type=\"checkbox\" ><label for=\"sk-estimator-id-107\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-108\" type=\"checkbox\" ><label for=\"sk-estimator-id-108\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-109\" type=\"checkbox\" ><label for=\"sk-estimator-id-109\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-110\" type=\"checkbox\" ><label for=\"sk-estimator-id-110\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['distance_closest_busstop', 'area_km2', 'couple_children_0_to_5_years',\n",
       "       'couple_children_18_or_above', 'couple_children_6_to_17_years',\n",
       "       'couple_without_children_x', 'single_parent_...\n",
       "                                                     max_leaves=None,\n",
       "                                                     min_child_weight=None,\n",
       "                                                     missing=nan,\n",
       "                                                     monotone_constraints=None,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     num_parallel_tree=None,\n",
       "                                                     predictor=None,\n",
       "                                                     random_state=None,\n",
       "                                                     reg_alpha=None,\n",
       "                                                     reg_lambda=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgbregressor__max_depth': [2, 3, 5, 7, 10],\n",
       "                         'xgbregressor__n_estimators': [10, 100]},\n",
       "             scoring=make_scorer(error, greater_is_better=False), verbose=4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=-0.828):\n",
      "{'xgbregressor__max_depth': 2, 'xgbregressor__n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'xgbregressor__gamma': 0.1, 'xgbregressor__learning_rate': 0.1, 'xgbregressor__max_depth': 4, 'xgbregressor__min_child_weight': 1, 'xgbregressor__n_estimators': 100, 'xgbregressor__objective': 'reg:squarederror'}, {'xgbregressor__gamma': 0.1, 'xgbregressor__learning_rate': 0.1, 'xgbregressor__max_depth': 4, 'xgbregressor__min_child_weight': 1, 'xgbregressor__n_estimators': 100, 'xgbregressor__objective': 'reg:squaredlogerror'}, {'xgbregressor__gamma': 0.1, 'xgbregressor__learning_rate': 0.1, 'xgbregressor__max_depth': 4, 'xgbregressor__min_child_weight': 1, 'xgbregressor__n_estimators': 100, 'xgbregressor__objective': 'reg:pseudohubererror'}, {'xgbregressor__gamma': 0.1, 'xgbregressor__learning_rate': 0.1, 'xgbregressor__max_depth': 4, 'xgbregressor__min_child_weight': 1, 'xgbregressor__n_estimators': 100, 'xgbregressor__objective': 'reg:tweedie'}]\n"
     ]
    }
   ],
   "source": [
    "print(search.cv_results_[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tdt4173')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a1013845248e30736e18085f9632598af74800f63e4cdc02bac7c14c90f9e84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
