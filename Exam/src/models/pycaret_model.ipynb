{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../own_data/all_with_stores_pop.csv\")\n",
    "all_data.set_index([\"dataset\", \"range_index\"], inplace=True)\n",
    "all_data['in_mall'] = all_data['mall_name'].notna()\n",
    "all_data['in_chain'] = all_data['chain_name'].notna()\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"Mangler type\")\n",
    "all_data['mall_name'] = all_data['mall_name'].fillna(\"None\")\n",
    "# all_data['address'] = all_data['address'].fillna(\"None\")\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"None\")\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"None\")\n",
    "all_data['as'] = all_data['store_name'].str.contains(r\"\\b(AS)\\b\", case=False, regex=True)\n",
    "all_data['chain_name'] = all_data['chain_name'].fillna(\"None\")\n",
    "all_data['busstop_id'] = all_data['busstop_id'].map(str)\n",
    "all_data['lv1'] = all_data['lv1'].map(str)\n",
    "all_data['lv2'] = all_data['lv2'].map(str)\n",
    "all_data['lv3'] = all_data['lv3'].map(str)\n",
    "all_data['lv4'] = all_data['lv4'].map(str)\n",
    "all_data.drop(columns=[\n",
    "    'store_name', \n",
    "    'stopplace_type', \n",
    "    'address', \n",
    "    \"importance_level\", \n",
    "    \"mall_name\", \n",
    "    \"busstop_id\", \n",
    "    # 'other_stores_50', 'buss_stops_1000', 'buss_stops_300',\n",
    "    # \"municipality_name\", \n",
    "    \"lv1\", \n",
    "    \"lv2\", \n",
    "   #  \"lv3\", \n",
    "    \"grunnkrets_id\", \n",
    "   #  'distance_closest_busstop',\n",
    "    \"lat\", \n",
    "    \"lon\", \n",
    "    \"area_km2\", \n",
    "    # 'other_stores_50', \n",
    "    # 'buss_stops_1000', 'couple_children_0_to_5_years', 'couple_children_18_or_above',\n",
    "    'couple_children_6_to_17_years', 'couple_without_children_x',\n",
    "    'single_parent_children_0_to_5_years',\n",
    "    'single_parent_children_18_or_above',\n",
    "    'single_parent_children_6_to_17_years', 'singles_x', 'singles_y', 'couple_without_children_y', 'couple_with_children',\n",
    "    'other_households', \n",
    "    'single_parent_with_children',\n",
    "    'couple_children_0_to_5_years', 'couple_children_18_or_above',\n",
    "    'side_placement',\n",
    "      #  'num_of_buss_stops_close', \n",
    "      #  'district_age_0-14_distribution',\n",
    "      #  'district_age_15-34_distribution', 'district_age_35-64_distribution',\n",
    "      #  'district_age_65-90_distribution', \n",
    "      'grunnkrets_population',\n",
    "      #  'municipality_density', \n",
    "      #  'district_density',\n",
    "       'all_households',\n",
    "        'lv1_population_district_div_count_stores',\n",
    "       'lv2_population_district_div_count_stores',\n",
    "       'lv1_population_municipality_div_count_stores',\n",
    "       'lv2_population_municipality_div_count_stores',\n",
    "       'in_mall',\n",
    "      #  'lv3_population_district_div_count_stores',\n",
    "      #  'lv4_population_district_div_count_stores',\n",
    "      #  'lv3_population_municipality_div_count_stores',\n",
    "      #  'lv4_population_municipality_div_count_stores',\n",
    "    # 'other_stores_1000', \n",
    "    # 'other_stores_250',\n",
    "   #  'municipality_population', \n",
    "   #  'district_population', \n",
    "   #  'other_stores_100',\n",
    "\n",
    "    'district_area',\n",
    "    'municipality_area',\n",
    "    # 'in_mall',\n",
    "      #  'in_chain',\n",
    "    # 'buss_stops_300'\n",
    "   #  'lv3'\n",
    "\n",
    "    ], inplace=True)\n",
    "\n",
    "data_with_label = all_data.loc[[\"train\"]]\n",
    "\n",
    "data_with_label.set_index('store_id', inplace=True)\n",
    "data_without_label = all_data.loc[['test']]\n",
    "data_without_label.set_index('store_id', inplace=True)\n",
    "data_without_label.drop(columns=[\"revenue\"], inplace=True)\n",
    "\n",
    "X, y = data_with_label.loc[:, data_with_label.columns != 'revenue'], data_with_label['revenue']\n",
    "\n",
    "data_train, data_test = train_test_split(data_with_label, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = data_train.loc[:, data_train.columns != 'revenue'], data_train['revenue']\n",
    "X_test, y_test = data_test.loc[:, data_test.columns != 'revenue'], data_test['revenue']\n",
    "test_x_lv4 =[]\n",
    "test_y_lv4 = []\n",
    "# d = [\"1.1.6.2\"]\n",
    "plaace_lv4 = ['1.1.1.0', '1.1.2.0', '1.1.3.0', '1.1.4.0', '1.1.5.0', '1.1.6.1',\n",
    "       '1.1.6.2', '1.1.6.3', '1.1.6.4', '1.1.7.0', '1.1.9.0', '1.2.1.0',\n",
    "       '1.2.2.0', '1.2.3.0', '1.2.4.0', '1.3.1.0', '1.3.2.0', '1.4.1.0',\n",
    "       '1.4.2.0', '2.1.1.0', '2.1.2.0', '2.1.3.0', '2.1.4.0', '2.1.5.0',\n",
    "       '2.1.6.0', '2.1.7.0', '2.2.1.0', '2.2.2.0', '2.2.4.0', '2.3.1.0',\n",
    "       '2.3.2.0', '2.3.3.0', '2.3.4.0', '2.3.5.0', '2.4.1.0', '2.4.2.0',\n",
    "       '2.4.3.0', '2.4.4.0', '2.4.5.0', '2.4.6.0', '2.5.2.0', '2.6.1.0',\n",
    "       '2.6.2.0', '2.6.3.1', '2.6.3.2', '2.6.3.3', '2.6.4.0', '2.6.5.0',\n",
    "       '2.6.6.1', '2.6.6.2', '2.7.1.0', '2.7.2.0', '2.7.3.0', '2.7.4.0',\n",
    "       '2.7.5.0', '2.7.6.0', '2.8.1.0', '2.8.10.0', '2.8.11.2', '2.8.2.0',\n",
    "       '2.8.3.0', '2.8.4.0', '2.8.5.0', '2.8.6.0', '2.8.7.0', '2.9.1.0',\n",
    "       '2.9.2.0', '2.9.3.0', '2.9.4.0', '2.9.5.0', '2.9.7.0', '2.9.8.0',\n",
    "       '2.9.9.0', '3.2.1.0', '3.2.2.0', '3.2.4.0', '3.3.2.0', '3.3.3.0',\n",
    "       '3.3.4.0', '3.3.5.0', '3.3.6.0', '3.3.7.0', '3.4.2.0', '3.4.3.0',\n",
    "       '3.6.1.0']\n",
    "# for lv_4 in plaace_lv4:\n",
    "#    lv4_data = data_test[data_test[\"lv4\"] == lv_4]\n",
    "#    test_slit_x_lv4, test_split_y_lv4 = lv4_data.loc[:, lv4_data.columns != 'revenue'], lv4_data['revenue']\n",
    "#    test_x_lv4.append(test_slit_x_lv4)\n",
    "#    test_y_lv4.append(test_split_y_lv4)\n",
    "y_train_scaled = np.log1p(y_train)\n",
    "y_test_scaled = np.log1p(y_test)\n",
    "y_scaled = np.log1p(y)\n",
    "\n",
    "\n",
    "# Comment in this when testing on test dataset to kaggle\n",
    "# X_train = X\n",
    "# y_train = y\n",
    "# y_train_scaled = y_scaled\n",
    "# X_test = data_without_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "s = setup(data_train, target = 'revenue', normalize = True, transformation = True, transform_target = True, \n",
    "                 remove_multicollinearity = True, multicollinearity_threshold = 0.95,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>17:43:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Lasso Least Angle Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            \n",
       "                                                                            \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                      17:43:14\n",
       "Status     . . . . . . . . . . . . . . . . . .              Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Lasso Least Angle Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, MAE, MSE, RMSE, R2, RMSLE, MAPE, TT (Sec)]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5738e594964941b9b6a1db9508d2d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/pycaret_model.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btdt4173-25.idi.ntnu.no/lhome/haaknes/ntnuhome/tdt-4173-revenue/src/models/pycaret_model.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m compare_models(sort \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mRMSE\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/utils/generic.py:950\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[39mif\u001b[39;00m globals_d[name] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/regression/functional.py:806\u001b[0m, in \u001b[0;36mcompare_models\u001b[0;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, engine, verbose, parallel)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39m@check_if_global_is_not_none\u001b[39m(\u001b[39mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[1;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompare_models\u001b[39m(\n\u001b[1;32m    672\u001b[0m     include: Optional[List[Union[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m     parallel: Optional[ParallelBackend] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    688\u001b[0m ):\n\u001b[1;32m    690\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39m    This function trains and evaluates performance of all estimators available in the\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[39m    model library using cross validation. The output of this function is a score grid\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m \n\u001b[1;32m    805\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m     \u001b[39mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[39m.\u001b[39;49mcompare_models(\n\u001b[1;32m    807\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m    808\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    809\u001b[0m         fold\u001b[39m=\u001b[39;49mfold,\n\u001b[1;32m    810\u001b[0m         \u001b[39mround\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mround\u001b[39;49m,\n\u001b[1;32m    811\u001b[0m         cross_validation\u001b[39m=\u001b[39;49mcross_validation,\n\u001b[1;32m    812\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    813\u001b[0m         n_select\u001b[39m=\u001b[39;49mn_select,\n\u001b[1;32m    814\u001b[0m         budget_time\u001b[39m=\u001b[39;49mbudget_time,\n\u001b[1;32m    815\u001b[0m         turbo\u001b[39m=\u001b[39;49mturbo,\n\u001b[1;32m    816\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    817\u001b[0m         fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m    818\u001b[0m         groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    819\u001b[0m         experiment_custom_tags\u001b[39m=\u001b[39;49mexperiment_custom_tags,\n\u001b[1;32m    820\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    821\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    822\u001b[0m         parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[1;32m    823\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/regression/oop.py:1119\u001b[0m, in \u001b[0;36mRegressionExperiment.compare_models\u001b[0;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, engine, verbose, parallel)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_engine(estimator\u001b[39m=\u001b[39mestimator, engine\u001b[39m=\u001b[39meng, severity\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     return_values \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcompare_models(\n\u001b[1;32m   1120\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m   1121\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m   1122\u001b[0m         fold\u001b[39m=\u001b[39;49mfold,\n\u001b[1;32m   1123\u001b[0m         \u001b[39mround\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mround\u001b[39;49m,\n\u001b[1;32m   1124\u001b[0m         cross_validation\u001b[39m=\u001b[39;49mcross_validation,\n\u001b[1;32m   1125\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   1126\u001b[0m         n_select\u001b[39m=\u001b[39;49mn_select,\n\u001b[1;32m   1127\u001b[0m         budget_time\u001b[39m=\u001b[39;49mbudget_time,\n\u001b[1;32m   1128\u001b[0m         turbo\u001b[39m=\u001b[39;49mturbo,\n\u001b[1;32m   1129\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   1130\u001b[0m         fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m   1131\u001b[0m         groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m   1132\u001b[0m         experiment_custom_tags\u001b[39m=\u001b[39;49mexperiment_custom_tags,\n\u001b[1;32m   1133\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1134\u001b[0m         parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[1;32m   1135\u001b[0m         caller_params\u001b[39m=\u001b[39;49mcaller_params,\n\u001b[1;32m   1136\u001b[0m     )\n\u001b[1;32m   1138\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1139\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[39m# Reset the models back to the default engines\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:793\u001b[0m, in \u001b[0;36m_SupervisedExperiment.compare_models\u001b[0;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, verbose, parallel, caller_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m         model, model_fit_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcreate_model_args)\n\u001b[1;32m    794\u001b[0m         model_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpull(pop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    795\u001b[0m         \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    796\u001b[0m             np\u001b[39m.\u001b[39msum(\n\u001b[1;32m    797\u001b[0m                 model_results\u001b[39m.\u001b[39mdrop(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    802\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:1522\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[0;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[39mreturn\u001b[39;00m model, model_fit_time\n\u001b[1;32m   1520\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m-> 1522\u001b[0m model, model_fit_time, model_results, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_model_with_cv(\n\u001b[1;32m   1523\u001b[0m     model,\n\u001b[1;32m   1524\u001b[0m     data_X,\n\u001b[1;32m   1525\u001b[0m     data_y,\n\u001b[1;32m   1526\u001b[0m     fit_kwargs,\n\u001b[1;32m   1527\u001b[0m     \u001b[39mround\u001b[39;49m,\n\u001b[1;32m   1528\u001b[0m     cv,\n\u001b[1;32m   1529\u001b[0m     groups,\n\u001b[1;32m   1530\u001b[0m     metrics,\n\u001b[1;32m   1531\u001b[0m     refit,\n\u001b[1;32m   1532\u001b[0m     system,\n\u001b[1;32m   1533\u001b[0m     display,\n\u001b[1;32m   1534\u001b[0m     return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m   1535\u001b[0m )\n\u001b[1;32m   1537\u001b[0m \u001b[39m# end runtime\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m runtime_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:1114\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[0;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, return_train_score)\u001b[0m\n\u001b[1;32m   1112\u001b[0m model_fit_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1113\u001b[0m \u001b[39mwith\u001b[39;00m redirect_output(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger):\n\u001b[0;32m-> 1114\u001b[0m     scores \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m   1115\u001b[0m         pipeline_with_model,\n\u001b[1;32m   1116\u001b[0m         data_X,\n\u001b[1;32m   1117\u001b[0m         data_y,\n\u001b[1;32m   1118\u001b[0m         cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m   1119\u001b[0m         groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m   1120\u001b[0m         scoring\u001b[39m=\u001b[39;49mmetrics_dict,\n\u001b[1;32m   1121\u001b[0m         fit_params\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m   1122\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m   1123\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m   1124\u001b[0m         error_score\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   1125\u001b[0m     )\n\u001b[1;32m   1126\u001b[0m model_fit_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1127\u001b[0m model_fit_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(model_fit_end \u001b[39m-\u001b[39m model_fit_start)\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_models(sort = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
