{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chain_name', 'mall_name', 'distance_closest_busstop', 'lv1', 'lv2', 'lv3', 'lv4', 'num_of_buss_stops_close', 'in_mall', 'in_chain']\n"
     ]
    }
   ],
   "source": [
    "without_gk = pd.read_csv(\"../../own_data/without_grunnkrets.csv\").set_index([\"dataset\", \"range_index\"])\n",
    "without_gk.drop(columns=['store_name', 'address', 'lat', 'lon', 'busstop_id', 'grunnkrets_id', 'importance_level', 'stopplace_type'], inplace=True)\n",
    "without_gk['in_mall'] = without_gk['mall_name'].notna()\n",
    "without_gk['in_chain'] = without_gk['chain_name'].notna()\n",
    "# without_gk['stopplace_type'] = without_gk['stopplace_type'].fillna(\"Mangler type\")\n",
    "without_gk['mall_name'] = without_gk['mall_name'].fillna(\"None\")\n",
    "without_gk['chain_name'] = without_gk['chain_name'].fillna(\"None\")\n",
    "\n",
    "\n",
    "data_with_label_wo = without_gk.loc[\"train\"]\n",
    "data_with_label_wo.set_index('store_id', inplace=True)\n",
    "X_, y_ = data_with_label_wo.loc[:, data_with_label_wo.columns != 'revenue'], data_with_label_wo['revenue']\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
    "print(X_.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chain_name', 'mall_name', 'distance_closest_busstop', 'district_name', 'municipality_name', 'area_km2', 'couple_children_0_to_5_years', 'couple_children_18_or_above', 'couple_children_6_to_17_years', 'couple_without_children_x', 'single_parent_children_0_to_5_years', 'single_parent_children_18_or_above', 'single_parent_children_6_to_17_years', 'singles_x', 'all_households', 'singles_y', 'couple_without_children_y', 'couple_with_children', 'other_households', 'single_parent_with_children', 'age_0', 'age_1', 'age_2', 'age_3', 'age_4', 'age_5', 'age_6', 'age_7', 'age_8', 'age_9', 'age_10', 'age_11', 'age_12', 'age_13', 'age_14', 'age_15', 'age_16', 'age_17', 'age_18', 'age_19', 'age_20', 'age_21', 'age_22', 'age_23', 'age_24', 'age_25', 'age_26', 'age_27', 'age_28', 'age_29', 'age_30', 'age_31', 'age_32', 'age_33', 'age_34', 'age_35', 'age_36', 'age_37', 'age_38', 'age_39', 'age_40', 'age_41', 'age_42', 'age_43', 'age_44', 'age_45', 'age_46', 'age_47', 'age_48', 'age_49', 'age_50', 'age_51', 'age_52', 'age_53', 'age_54', 'age_55', 'age_56', 'age_57', 'age_58', 'age_59', 'age_60', 'age_61', 'age_62', 'age_63', 'age_64', 'age_65', 'age_66', 'age_67', 'age_68', 'age_69', 'age_70', 'age_71', 'age_72', 'age_73', 'age_74', 'age_75', 'age_76', 'age_77', 'age_78', 'age_79', 'age_80', 'age_81', 'age_82', 'age_83', 'age_84', 'age_85', 'age_86', 'age_87', 'age_88', 'age_89', 'age_90', 'lv1', 'lv2', 'lv3', 'lv4', 'num_of_buss_stops_close', 'in_mall', 'in_chain']\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"../../own_data/all_merged.csv\").set_index([\"dataset\", \"range_index\"])\n",
    "all_data.drop(columns=['store_name', 'address', 'lat', 'lon', 'busstop_id', 'importance_level', 'stopplace_type', 'grunnkrets_id'], inplace=True)\n",
    "all_data['in_mall'] = all_data['mall_name'].notna()\n",
    "all_data['in_chain'] = all_data['chain_name'].notna()\n",
    "# all_data['stopplace_type'] = all_data['stopplace_type'].fillna(\"Mangler type\")\n",
    "all_data['mall_name'] = all_data['mall_name'].fillna(\"None\")\n",
    "all_data['chain_name'] = all_data['chain_name'].fillna(\"None\")\n",
    "\n",
    "\n",
    "data_with_label = all_data.loc[\"train\"]\n",
    "data_with_label.set_index('store_id', inplace=True)\n",
    "X, y = data_with_label.loc[:, data_with_label.columns != 'revenue'], data_with_label['revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_scaled = np.log1p(y_train)\n",
    "print(X.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(data_with_label.loc[data_with_label.isnull()].isna().sum())\n",
    "data_with_label.columns[data_with_label.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore'), \n",
    "    ['municipality_name',\n",
    "    'chain_name', \n",
    "    'mall_name', \n",
    "    'district_name',\n",
    "    'lv1',\n",
    "    'lv2',\n",
    "    'lv3',\n",
    "    'lv4']),\n",
    "    remainder=\"passthrough\")\n",
    "grad = GradientBoostingRegressor(random_state=42, learning_rate=.2, n_estimators=1000, loss=\"squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans_ = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore'), \n",
    "    ['chain_name', \n",
    "    'mall_name', \n",
    "    'lv1',\n",
    "    'lv2',\n",
    "    'lv3',\n",
    "    'lv4']),\n",
    "    remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10287x946 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 86880 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_trans.fit_transform(X_train)\n",
    "column_trans_.fit_transform(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(column_trans, grad)\n",
    "pipe_ = make_pipeline(column_trans_, grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train_scaled)\n",
    "y_hat = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error \n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): n-dimensional vector of ground-truth values \n",
    "        y_pred (np.array): n-dimensional vecotr of predicted values \n",
    "    \n",
    "    Returns:\n",
    "        A scalar float with the rmsle value \n",
    "    \n",
    "    Note: You can alternatively use sklearn and just do: \n",
    "        `sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5`\n",
    "    \"\"\"\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    assert (y_true >= 0).all(), 'Received negative y_true values'\n",
    "    assert (y_pred >= 0).all(), 'Received negative y_pred values'\n",
    "    assert y_true.shape == y_pred.shape, 'y_true and y_pred have different shapes'\n",
    "    y_true_log1p = np.log1p(y_true)  # log(1 + y_true)\n",
    "    y_pred_log1p = np.log1p(y_pred)  # log(1 + y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_pred_log1p - y_true_log1p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273457588935354"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear error, no log before training\n",
    "rmsle(y_test, y_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7347577275646373"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squared error log before training\n",
    "rmsle(y_test, np.expm1(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "#print(cross_val_score(pipe, X, y, cv=5, scoring=rmsle_scorer))\n",
    "#print(cross_val_score(pipe, X_test, y_test, scoring=rmsle_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'gradientboostingregressor__loss': [\"absolute_error\"],\n",
    "          'gradientboostingregressor__n_estimators': [200, 500, 1000],\n",
    "          'gradientboostingregressor__learning_rate': [.2, .1]   }\n",
    "\n",
    "grid_1 = GridSearchCV(pipe_, params, cv=5, scoring=rmsle_scorer, verbose=3)\n",
    "grid_1.fit(X_, y_)\n",
    "print(\"No grunnpunkt data\")\n",
    "print(grid_1.best_params_)\n",
    "print(grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.796 total time=   3.4s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.732 total time=   3.0s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.717 total time=   3.0s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.769 total time=   3.1s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.731 total time=   3.2s\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.790 total time=   8.3s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.727 total time=   7.1s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.717 total time=  10.4s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.769 total time=   8.0s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.725 total time=   9.7s\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.789 total time=  19.9s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.724 total time=  16.7s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.717 total time=  15.1s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.769 total time=  14.8s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.727 total time=  16.3s\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.801 total time=   3.3s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.737 total time=   3.3s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.719 total time=   3.2s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.779 total time=   3.2s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=200;, score=-0.737 total time=   3.3s\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.791 total time=   8.0s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.728 total time=   8.3s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.719 total time=   7.9s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.774 total time=   8.2s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=500;, score=-0.730 total time=   8.1s\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.786 total time=  15.8s\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.726 total time=  16.8s\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.719 total time=  15.6s\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.771 total time=  15.2s\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.727 total time=  16.1s\n",
      "{'gradientboostingregressor__learning_rate': 0.2, 'gradientboostingregressor__loss': 'absolute_error', 'gradientboostingregressor__n_estimators': 1000}\n",
      "-0.745299889734268\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.780 total time= 2.1min\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.734 total time= 2.2min\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.705 total time= 2.1min\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.752 total time= 2.5min\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.752 total time= 2.0min\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.781 total time= 2.8min\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.734 total time= 2.6min\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.706 total time= 2.5min\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.754 total time= 2.3min\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1000;, score=-0.754 total time= 2.1min\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1200;, score=-0.782 total time= 3.1min\n",
      "[CV 2/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1200;, score=-0.735 total time= 3.2min\n",
      "[CV 3/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1200;, score=-0.705 total time= 2.9min\n",
      "[CV 4/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1200;, score=-0.754 total time= 3.1min\n",
      "[CV 5/5] END gradientboostingregressor__learning_rate=0.2, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=1200;, score=-0.752 total time= 3.1min\n",
      "[CV 1/5] END gradientboostingregressor__learning_rate=0.1, gradientboostingregressor__loss=absolute_error, gradientboostingregressor__n_estimators=800;, score=-0.775 total time= 2.3min\n"
     ]
    }
   ],
   "source": [
    "# params = {'adaboostregressor__base_estimator__max_depth':[5],\n",
    "#           'adaboostregressor__base_estimator__min_samples_leaf':[5,10],\n",
    "#           'adaboostregressor__n_estimators':[20, 40],\n",
    "#           'adaboostregressor__learning_rate':[0.0001,0.001],\n",
    "#           'adaboostregressor__loss': ['linear']}\n",
    "# params = {'randomforestregressor__max_depth': [20, 30]}\n",
    "params = {'gradientboostingregressor__loss': [\"absolute_error\"],\n",
    "          'gradientboostingregressor__n_estimators': [200, 500, 1000],\n",
    "          'gradientboostingregressor__learning_rate': [.2, .1]   }\n",
    "\n",
    "grid_1 = GridSearchCV(pipe_, params, cv=5, scoring=rmsle_scorer, verbose=3)\n",
    "grid_1.fit(X_, y_)\n",
    "print(\"No grunnpunkt data\")\n",
    "print(grid_1.best_params_)\n",
    "print(grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'gradientboostingregressor__loss': [\"absolute_error\"],\n",
    "          'gradientboostingregressor__n_estimators': [800, 1000, 1200],\n",
    "          'gradientboostingregressor__learning_rate': [.2, .1]   }\n",
    "\n",
    "grid_2 = GridSearchCV(pipe, params, cv=5, scoring=rmsle_scorer, verbose=3)\n",
    "grid_2.fit(X, y)\n",
    "\n",
    "print(\"With grunnpunkt data, but not all datapoints\")\n",
    "print(grid_2.best_params_)\n",
    "print(grid_2.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tdt4173')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a1013845248e30736e18085f9632598af74800f63e4cdc02bac7c14c90f9e84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
